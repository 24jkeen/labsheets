{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Intro to BlueCrystal and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first lab session, you will learn the basics on implementing deep learning models using TensorFlow 1.2 and how to use BlueCrystal Phase 4 (BC4) for training them. The aim it's to learn the methodology for building, debugging and training models using this framework, and you will start by training a shallow neural network for recognising objects using the CIFAR-10 dataset. \n",
    "\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "1.- Build your first deep learning model using TensorFlow 1.2 for recognising objects using the CIFAR-10 dataset. \n",
    "\n",
    "2.- Train your  model on BC4 and visualize the training process\n",
    "\n",
    "3.- Evaluate your model.\n",
    "\n",
    "The Lab sheet is divided on two sections: The first one describes how to use BlueCrytal 4 trough a terminal window from your machine while the second one gives a general overview about TensorFlow and the requiered steps to follow for building this very first Deep Learning Model. So by the end of the session  you will know how to use Blue Crystal 4 and be prepared for improving the model on the coming lab sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Blue Crystal Phase 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BlueCrystal Phase 4 (BC4) is the latest update on the University's High Performance Computing (HPC) machine. It includes 32 GPU-accelerated nodes, each of them with two NVIDIA Tesla P100 GPU accelerators and also a visualization node equipped with NVIDIA GRID GPUs; what matters to us are the Tesla P100 GPU accelerators that we will use for training your Deep Learing algorithms. \n",
    "\n",
    "**NOTE**: You may try to debug and run programs on your own machine, but sadly we are unable to offer assistance for installing and/or set-up of the dependencies on personal machines. \n",
    "\n",
    "\n",
    "There are two *modes* for using BC4: *Interactive* and *Job Submission*. We will use *Interactive* as much as possible during lab sessions, since allows the immediate excution of your program and you can see outputs directy on the terminal window (great for debugging); while the *Job Submission* method queues your job and generates files related with the excecution of your file. You will use *Job Submission* as part of CW2, so we will revisit that later.\n",
    "\n",
    "### 1.1.1   Copying files between your machine and BC4\n",
    "\n",
    "You need to copy the provided files CIFAR10 and Lab_0_Python_Intro (which contains <mark> ```simple_train_cifar.py, submit_job.sh, tensorboard_params.sh, go_interactive.sh```</mark>) to your account in BC4. For copying individual files from your machine to your home directory on BC4 use the next example with go_interactive.sh:\n",
    "\n",
    "\n",
    " <mark>```scp  /path_to_files/go_interactive.sh < your_UoB_ID >@bc4login.acrc.bris.ac.uk:```</mark>\n",
    "\n",
    "or all files at once by using: \n",
    "\n",
    " <mark>```scp -r /path_to_files/   < your_UoB_ID >@bc4login.acrc.bris.ac.uk:```</mark>\n",
    "\n",
    "For copying files from BC4 to your machine use the  command ```scp``` from a terminal on your machine, you can copy individual files, as well as directories:\n",
    "\n",
    " <mark>```scp  < your_UoB_ID >@bc4login.acrc.bris.ac.uk:/path_to_files/foo.foo   /path_in_your_machine/```</mark>\n",
    " \n",
    " \n",
    " You should see something like this on your home directory:\n",
    " \n",
    " ```\n",
    " CIFAR10\n",
    " Lab_1_intro\n",
    " |----------simple_train_cifar.py \n",
    " |----------submit_job.sh \n",
    " |----------tensorboard_params.sh \n",
    " |----------go_interactive.sh```\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2  Logging in, running scripts  and managing your directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicate the next steps for logging-in and running files on BC4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* **For logging in:** \n",
    "\n",
    "The connection to BC4 is done via SSH, thus open a new Terminal window and type: \n",
    "\n",
    "ssh < your_UoB_ID >@bc4login.acrc.bris.ac.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running your scripts interactively\n",
    "\n",
    "For running jobs interactively, excute the script <mark>``` go_interactive.sh```</mark> (type <mark>``` chmod +x go_interactive.sh```</mark>  if requiered). You should see how the current directory changes from [<USER_NAME>@bc4login2 ...] to [<USER_NAME>@gpuID ...], denotating the assigned GPU  for switching to *interactive mode* on BC4. Then you can run the python scripts by simple typing:\n",
    "\n",
    "<mark>```python foo.py  ```</mark> \n",
    "\n",
    "** After your script has finished, close the interactive mode (which also releases the GPU node), by typing <mark>```close ```</mark>. Type <mark>```close```</mark> again for closing your BC4 session. **\n",
    "\n",
    "Complete the rest of the Lab Sheet before running the training script, it will help you to understand what is happening during the training process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the Job submission method \n",
    "\n",
    "During the course it may ocurr that very few GPUs are available due maintenace, other people using them, unforseen events, etc. making not possible to use the *Interactive Session* previously described. So then you will have to use the *Job Submission method*. To do this stablish a connection to BC4 as described before. Open the file \"submit_job.sh\" using emacs or vim for example, and **modify line #10** for including your email and recieve notifications about the jobs you're submitting and **modify line #12** for the filename your . Now run the next command for submitting a job to the BC4 queueing system:\n",
    "\n",
    "sbatch submit_job.sh\n",
    "\n",
    "And you should see a generated files (hostname_< job_number >.err  hostname_< job_number >.out) that shows the outputs after running your python script.On the hostname_< job_number >.out you should see output that you normally see on the terminal window when your using the Interactive mode,  hostname_< job_number >.err shows errors ocurred during that caused an unsuccessful runnning of your scripts.\n",
    "\n",
    "Again, keep following the lab sheet before trying these commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 TensorFlow-1.2\n",
    "\n",
    "TensorFlow was originally developed by the Google Brain team as an internal machine learning tool and was open sourced under the Apache 2.0 License in November 2015. Since then, it has become a popular choice among researchers and companies due to its balanced trade-off between flexibility (requiered in research) and production-worthiness (requiered in industry). Additionally, it's well documented and maintained, backed by a large community (> 10,000 commits and > 3000 TF-related repos in one year). \n",
    "\n",
    "Its core is written in C++, with Python, C++, Java and Go frontends. For the lab sessions we will the ** 1.2 version** with **Python** as frontend due to its compatibility with Numpy and the TF.Learn and TF-Slim APIs that will become handy later on.\n",
    "\n",
    "> Note that TF.Learn is different from the independant project [tflearn](http://tflearn.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Graphs and sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow does all its computation in graphs (creators referred to them as **dataflow graph**), [Danijar Hafner's website](https://danijar.com/what-is-a-tensorflow-session/) and [TensorFlow's documentation](https://www.tensorflow.org/programmers_guide/graphs) contains more details about the concept of computational graphs and their advantages, in this Lab we will focus only on how to build and excecute them.\n",
    "\n",
    "The **graph** will define the variables and computation. It doesnâ€™t compute anything neither hold any values, it just defines the operations that we want to be perfermed.\n",
    "\n",
    "The excecution of the graph, referred as **session**, allocates resources, feeds the data, computes the operations and holds the values of intermediate results and variables. Figure below shows how the data flow from the *input readers*, to *opertations* such as convolutions and activations, then the *gradients* are computed and error is *backpropagated* to the *weight* and *bias variables*. \n",
    "\n",
    "![](https://www.tensorflow.org/images/tensors_flowing.gif)\n",
    "\n",
    "\n",
    "**We encourage to use single graphs and single session** for your models in this course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Variables and Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tensor Variables* such as Weights ($W$) and Biases ($b$) for Convolutional Neural Networks (CNNs) are declared  via the  <mark>```tf.Variable ```</mark> class, while for *Tensor Constants* there are several numpy-like methods such as <mark>```tf.zeros, tf.ones, tf.constant, etc.```</mark>, for this lab we will use only *Tensor Variables*, [here](https://www.tensorflow.org/api_guides/python/constant_op) you can see how to use constants if your requiere them later on. \n",
    "\n",
    "We will use the function <mark> ```tf.Variable()```</mark>   for creating  variables and they need to be intiliazed  <mark>``` tf.Variable(<initial-value>, name=<optional-name>)```</mark> at the definition step; for this, we will use random truncated initialization by using the <mark>```tf.truncated_normal(shape, stddev)```</mark> method.\n",
    "\n",
    "With the *Tensor Variables* we can perform *arithmetic*, *basic math*, *matrix math* and *sequence indexing*   operations, check  [math operations](https://www.tensorflow.org/api_guides/python/math_ops),  common operations for neural networks such as *convolutions*, *activations*, *pooling*, *recurrent architechtures* etc. on are defined on [ Neural Network operations](https://www.tensorflow.org/api_guides/python/nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Building your first Model\n",
    "\n",
    "Next, we will describe the code in the  <mark> ```simple_train_cifar.py```</mark> file for implementing a CNN for recognising objects on the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. Your very first deep learning model will be formed by two Convolutional Layers and two Fully connected layers with next size and hyperparameters. \n",
    "\n",
    "* Filter 5 x 5, with stride 1 and padding 'SAME' for convolutions\n",
    "* Kernel 2 x 2 , with stride 2 and padding 'SAME' for max pooling \n",
    "* 1024 Neurons for the Fully Connected layer\n",
    "* ReLU as Activation function for convolutions and fully connected layer\n",
    "* Initialization using random values from a truncated normal distribution with $\\sigma= 0.1$  and $\\mu=0$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "We first begin with the imports that the lab will require, most of which are pretty standard python imports. We will use ```FLAGS``` for parsing values to the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'CIFAR10'))\n",
    "import cifar10 as cf\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('data_dir', os.getcwd() + '/dataset/',\n",
    "                           \"\"\"Directory where the dataset will be stored \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 1000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('log_frequency', 10,\n",
    "                            \"\"\"Number of steps to log results to the console and save summaries\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_model', 1000,\n",
    "                            \"\"\"Number of steps for saving the model periodically\"\"\")\n",
    "\n",
    "# Optimisation hyperparameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 128,\n",
    "                            \"\"\"How often to log results to the console.\"\"\")\n",
    "tf.app.flags.DEFINE_float('learning_rate', 1e-4, \n",
    "                                \"\"\"Number of examples to run.\"\"\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('img_width', 32,\n",
    "                            \"Image width\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('img_height', 32,\n",
    "                            \"Image height\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('img_channels', 3,\n",
    "                            \"Image channels\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_classes', 10,\n",
    "                            \"Num classes\")\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', os.getcwd() + '/logs/exp_bs_'+str(FLAGS.batch_size)+\"_lr_\"+str(FLAGS.learning_rate),\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Convolutional and Pooling Layers\n",
    "We can now define a function which will create a 2D convolutional layer with full stride and a max pooling layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "def conv2d(x, W):\n",
    "  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name='convolution')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "  #\"name: name for operation\"\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name='pooling')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight and Bias Variables\n",
    "Next we can define functions that will create weight and bias variables of given shapes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "def weight_variable(shape):\n",
    "  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name='weights')\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name='biases')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the CNN\n",
    "With the previous code we can now define and create our CNN. As mentioned previously we want to have:\n",
    "* Convolutional Layer - Conv1\n",
    "* Pooling Layer - Pool1\n",
    "* Convolutional Layer - Conv2\n",
    "* Pooling Layer - Pool2\n",
    "* Fully Connected Layer - FC1\n",
    "* An Output Layer - FC2\n",
    "\n",
    "We first create a function, deepnn(x) which will take in our image and return the class probabilities. In here we also initialise some variables we will use later when creating the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "def deepnn(x):\n",
    "  \"\"\"deepnn builds the graph for a deep net for classifying digits.\n",
    "\n",
    "  Args:\n",
    "    x: an input tensor with the dimensions (N_examples, 3072), where 3072 is the\n",
    "    number of pixels in a standard CIFAR10 image.\n",
    "\n",
    "  Returns:\n",
    "    y: is a tensor of shape (N_examples, 10), with values\n",
    "    equal to the logits of classifying the digit into one of 10 classes (the\n",
    "    digits 0-9). \n",
    "    img_summary: Returns a string tensor containing sampled input images.\n",
    "  \"\"\"\n",
    "  # Reshape to use within a convolutional neural net.\n",
    "  # Last dimension is for \"features\" - it would be 1 one for a grayscale image,\n",
    "  # 3 for an RGB image, 4 for RGBA, etc.\n",
    "\n",
    "  x_image = tf.reshape(x, [-1, FLAGS.img_width, FLAGS.img_height, FLAGS.img_channels])\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that finished the following code defines the layers inside your CNN.\n",
    "Even though the code is provided look at each step as to what inputs the layer takes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "``` python\n",
    "# First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "  with tf.variable_scope(\"Conv_1\") as scope:\n",
    "    W_conv1 = weight_variable([5, 5, FLAGS.img_channels, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "    # Pooling layer - downsamples by 2X.\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "  with tf.variable_scope(\"Conv_2\") as scope:\n",
    "\n",
    "    # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    \n",
    "    # Second pooling layer.\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "  with tf.variable_scope(\"FC_1\") as scope:\n",
    "\n",
    "    # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "    # is down to 8x8x64 feature maps -- maps this to 1024 features.\n",
    "    \n",
    "    W_fc1 = weight_variable([8 * 8 * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    \n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 8*8*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "  with tf.variable_scope(\"FC_2\") as scope:  \n",
    "\n",
    "    # Map the 1024 features to 10 classes, one for each digit\n",
    "    W_fc2 = weight_variable([1024, FLAGS.num_classes])\n",
    "    b_fc2 = bias_variable([FLAGS.num_classes])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "    \n",
    "  return y_conv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now declare a session to make use of the graph, and check on TensorBoard that all the conections and data feeding are in the right place with a main function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "def main(_):\n",
    "  tf.reset_default_graph()\n",
    "\n",
    "  # Import data\n",
    "  cifar = cf.cifar10(batchSize=FLAGS.batch_size, downloadDir=FLAGS.data_dir)\n",
    "\n",
    "  with tf.variable_scope(\"inputs\") as scope:\n",
    "\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.float32, [None, FLAGS.img_width * FLAGS.img_height * FLAGS.img_channels])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, FLAGS.num_classes])\n",
    "\n",
    "  # Build the graph for the deep net\n",
    "  y_conv = deepnn(x)\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # For loop for train and validation\n",
    "\n",
    "    for step in range(FLAGS.max_steps):\n",
    "\n",
    "      # Training ----------------------------------------------------------------------------------------------------\n",
    "      # Backpropagation using train set\n",
    "\n",
    "      (trainImages, trainLabels) = cifar.getTrainBatch()\n",
    "      (testImages, testLabels) = cifar.getTestBatch()   \n",
    "\n",
    "      sess.run(train_step, feed_dict={x: trainImages, y_: trainLabels})\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "  tf.app.run(main=main)\n",
    "  \n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4. Optimisation and Gradient Descent\n",
    "\n",
    "Now that we have a CNN we want to actually train it! Include a loss function, we're using the standard cross entropy loss between the logits and the labels from the groundtruth. You can add the following in your main function below where you build your CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ```python\n",
    "with tf.variable_scope(\"x_entropy\") as scope:\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "  \n",
    "train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name='accuracy')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write the main training loop inside of the main function inside the tensorflow session. We run the loop 10,000 times however we only bother printing out the training information every 100 steps. Note we do not have to write any derivatives explicitely due to TensorFlow's [Automatic Differentiation](http://www.columbia.edu/~ahd2125/post/2015/12/5/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "for step in range(FLAGS.max_steps):\n",
    "\n",
    "      # Training ------------------------------------------------------------------------------------------------\n",
    "      # Backpropagation using train set\n",
    "\n",
    "      (trainImages, trainLabels) = cifar.getTrainBatch()\n",
    "      (testImages, testLabels) = cifar.getTestBatch()   \n",
    "\n",
    "      sess.run(train_step, feed_dict={x: trainImages, y_: trainLabels})\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined everything your TF model needs to be trained, so we only need to include some code for visualising the training progess and saving checkpoints:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5. Summaries and Tensorboard\n",
    "Tensorboard allows for visualisation of training and testing statistics in addition to a graphical output of the CNN that was trained. To do this we can run tensorboard on Blue Crystal and via the use of port forwarding view the results on the lab machines. \n",
    "\n",
    "First we need to indicate what we want to be save on the summaries, for now we will save some images that are feed in to model, the loss and accuracy reached on every batch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    ".\n",
    ".\n",
    ".\n",
    "# Feeding data section\n",
    ".\n",
    ".\n",
    ".\n",
    "# For visualising images that are feed to the model: \n",
    "tf.summary.image('Input_images',x_image)\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    "# Optimisation section\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "# For visualing the loss value on current batch:\n",
    "tf.summary.scalar(\"Loss\", cross_entropy)\n",
    "\n",
    "# For visualing the accuracy on the current batch:\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "\n",
    "# For combining all the summaries per step:\n",
    "summary_op =tf.summary.merge_all()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(FLAGS.train_dir + \"_train\", sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # For loop for train and validation\n",
    "\n",
    "    for step in range(FLAGS.max_steps):\n",
    "\n",
    "      # Training -----------------------------------------------------------------------------------------------------------------------------------\n",
    "      # Backpropagation using test set\n",
    "\n",
    "      (trainImages, trainLabels) = cifar.getTrainBatch()\n",
    "      (testImages, testLabels) = cifar.getTestBatch()   \n",
    "\n",
    "      _,summary_str = sess.run([train_step, training_summary], feed_dict={x: trainImages, y_: trainLabels})\n",
    "\n",
    "      if step % (FLAGS.log_frequency)== 0 :\n",
    "        summary_writer.add_summary(summary_str, step)\n",
    "        \n",
    "        ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6. Saving checkpoints\n",
    "\n",
    "Lastly, we include a saver for saving checkpoints so you can use them as a backup of your training and for later evaluation of your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "...\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ...\n",
    "    \n",
    "    # Save the model checkpoint periodically.\n",
    "      if step % FLAGS.save_model == 0 or (step + 1) == FLAGS.max_steps:\n",
    "        checkpoint_path = os.path.join(FLAGS.train_dir + \"_train\", 'model.ckpt')\n",
    "        saver.save(sess, checkpoint_path, global_step=step)\n",
    "    ...\n",
    "    \n",
    "    ```\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 Training your first CNN.\n",
    "\n",
    "\n",
    "**It's finally here, the moment you've been waiting for!**  Follow the next steps for running the training script:\n",
    "\n",
    "1. Login to BC4, go to the directory  \" ```Lab_1_Python_Intro/``` and make all .sh files executables by using the command ```chmod ```: \n",
    "\n",
    "   ``` chmod +x go_interactive.sh submit_job.sh tensorboard_params.sh```\n",
    "\n",
    "2. Type   ./go_interactive.sh  to switch to interactive mode.\n",
    "\n",
    "3. Run the script ```tensorboard_params.sh```. It will pop up two values: ipnport=XXXXX ipnip=XX.XXX.X.X. Write them down since we will use them for using TensorBoard.\n",
    "\n",
    "4. Type  <mark>```python simple_train_cifar.py & tensorboard --logdir=logs/ --port=ipnport```</mark>, where ipnport comes from the previous step. You will a line saying about the dataset being downloaded. It might take a minute or two before you start seeing the accuracy on the validation batch at every step\n",
    "\n",
    "5. Open a new Terminal window on your machine and type: <mark>``` ssh  <USER_NAME>@bc4login.acrc.bris.ac.uk -L 6006:<ipnip>:<ipnport>```</mark>, where **ipnip** and **ipnport** comes from step 2.\n",
    "\n",
    "6. Open your web browser (we recommend using Chrome) and open the port 6006. Type [here](http://localhost:6006/) to do that. That should open TensorBoard, and you can navigate trough the summaries that we included. \n",
    "\n",
    "7. Once the training has finished, **close the interactive session** by typying Ctrl + followed by ```exit``, you shoukd see how your working directory returns to [<username>@bc4login], **please make sure closing your session in order to release the gpu node**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using TensorBoard you can monitor the training process, on the following Labs you will perform experiments  by varying hyperparemeters such as learning rate, batch size, epochs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.8 Validating and evaluating results\n",
    "\n",
    "Finally, below we show how to use the CIFAR-10's *test set*, in order to see how well the model performs for classifing unseen examples. Using validation and test sets helps to identify cases of under and overfitting, as well as for benchmarking the performance among different algorithms. In this Lab sessions will use the test set primarly for hyperparameters selection. Bare in mind that for this task, usually a subsampling of the training set (commonly detoned as *validation set*) is used for this task.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(FLAGS.train_dir + \"_train\", sess.graph)\n",
    "\n",
    "    summary_writer_validation = tf.summary.FileWriter(FLAGS.train_dir + \"_validate\", sess.graph)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(FLAGS.max_steps):\n",
    "      batch = mnist.train.next_batch(FLAGS.batch_size)\n",
    "      batch_validation = mnist.validation.next_batch(FLAGS.batch_size)\n",
    "      if step % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (step, train_accuracy))\n",
    "\n",
    "      if step % 101 == 0:\n",
    "        validation_accuracy, summary_str = sess.run([accuracy, summary_op], feed_dict={x: batch_validation[0], y_: batch_validation[1]})\n",
    "        print('step %d, validation accuracy %g' % (step, validation_accuracy))\n",
    "        summary_writer_validation.add_summary(summary_str, step)\n",
    "      \n",
    "      #train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "      _,summary_str = sess.run([train_step, summary_op], feed_dict={x: batch[0], y_: batch[1]})\n",
    "      \n",
    "      ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full training file\n",
    "The complete file for training that is used in this tutorial can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#                                                          #\n",
    "#  Code for Lab 1: Intro to TensorFlow and Blue Crystal 4  # \n",
    "#                                                          #\n",
    "############################################################\n",
    "\n",
    "\"\"\"Based on TensorFLow's tutorial: A deep MNIST classifier using convolutional layers.\n",
    "\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/pros\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'CIFAR10'))\n",
    "import cifar10 as cf\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('data_dir', os.getcwd() + '/dataset/',\n",
    "                           \"\"\"Directory where the dataset will be stored \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 1000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('log_frequency', 10,\n",
    "                            \"\"\"Number of steps to log results to the console and save summaries\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_model', 1000,\n",
    "                            \"\"\"Number of steps for saving the model periodically\"\"\")\n",
    "\n",
    "# Optimisation hyperparameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 128,\n",
    "                            \"\"\"How often to log results to the console.\"\"\")\n",
    "tf.app.flags.DEFINE_float('learning_rate', 1e-4, \n",
    "                                \"\"\"Number of examples to run.\"\"\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('img_width', 32,\n",
    "                            \"Image width\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('img_height', 32,\n",
    "                            \"Image height\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('img_channels', 3,\n",
    "                            \"Image channels\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_classes', 10,\n",
    "                            \"Num classes\")\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', os.getcwd() + '/logs/exp_bs_'+str(FLAGS.batch_size)+\"_lr_\"+str(FLAGS.learning_rate),\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "\n",
    "\n",
    "def deepnn(x):\n",
    "  \"\"\"deepnn builds the graph for a deep net for classifying digits.\n",
    "\n",
    "  Args:\n",
    "    x: an input tensor with the dimensions (N_examples, 3072), where 3072 is the\n",
    "    number of pixels in a standard CIFAR10 image.\n",
    "\n",
    "  Returns:\n",
    "    y: is a tensor of shape (N_examples, 10), with values\n",
    "    equal to the logits of classifying the digit into one of 10 classes (the\n",
    "    digits 0-9). \n",
    "    img_summary: Returns a string tensor containing sampled input images.\n",
    "  \"\"\"\n",
    "  # Reshape to use within a convolutional neural net.\n",
    "  # Last dimension is for \"features\" - it would be 1 one for a grayscale image,\n",
    "  # 3 for an RGB image, 4 for RGBA, etc.\n",
    "\n",
    "  x_image = tf.reshape(x, [-1, FLAGS.img_width, FLAGS.img_height, FLAGS.img_channels])\n",
    "\n",
    "  img_summary = tf.summary.image('Input_images',x_image)\n",
    "\n",
    "  # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "  with tf.variable_scope(\"Conv_1\") as scope:\n",
    "    W_conv1 = weight_variable([5, 5, FLAGS.img_channels, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "    # Pooling layer - downsamples by 2X.\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "  with tf.variable_scope(\"Conv_2\") as scope:\n",
    "\n",
    "    # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    \n",
    "    # Second pooling layer.\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "  with tf.variable_scope(\"FC_1\") as scope:\n",
    "\n",
    "    # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "    # is down to 8x8x64 feature maps -- maps this to 1024 features.\n",
    "    \n",
    "    W_fc1 = weight_variable([8 * 8 * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    \n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 8*8*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "  with tf.variable_scope(\"FC_2\") as scope:  \n",
    "\n",
    "    # Map the 1024 features to 10 classes, one for each digit\n",
    "    W_fc2 = weight_variable([1024, FLAGS.num_classes])\n",
    "    b_fc2 = bias_variable([FLAGS.num_classes])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "  return y_conv, img_summary\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name='convolution')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "  #\"name: name for operation\"\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name='pooling')\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name='weights')\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name='biases')\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  tf.reset_default_graph()\n",
    "\n",
    "  # Import data\n",
    "  cifar = cf.cifar10(batchSize=FLAGS.batch_size, downloadDir=FLAGS.data_dir)\n",
    "\n",
    "  with tf.variable_scope(\"inputs\") as scope:\n",
    "\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.float32, [None, FLAGS.img_width * FLAGS.img_height * FLAGS.img_channels])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, FLAGS.num_classes])\n",
    "\n",
    "  # Build the graph for the deep net\n",
    "  y_conv, img_summary = deepnn(x)\n",
    "\n",
    "  with tf.variable_scope(\"x_entropy\") as scope:\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "  \n",
    "  train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(cross_entropy)\n",
    "\n",
    "  correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "  \n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name='accuracy')\n",
    "\n",
    "  loss_summary =  tf.summary.scalar(\"Loss\", cross_entropy)\n",
    "  \n",
    "  acc_summary =  tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "  \n",
    "  # summaries for TensorBoard visualisation\n",
    "\n",
    "  validation_summary = tf.summary.merge([img_summary,acc_summary])\n",
    "  training_summary = tf.summary.merge([img_summary,loss_summary]) \n",
    "  test_summary = tf.summary.merge([img_summary,acc_summary])\n",
    "  \n",
    "  # saver for checkpoints\n",
    "  saver = tf.train.Saver(tf.global_variables(), max_to_keep=1)\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(FLAGS.train_dir + \"_train\", sess.graph)\n",
    "    summary_writer_validation = tf.summary.FileWriter(FLAGS.train_dir + \"_validate\", sess.graph)\n",
    "    summary_writer_test = tf.summary.FileWriter(FLAGS.train_dir + \"_test\", sess.graph)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # For loop for train and validation\n",
    "\n",
    "    for step in range(FLAGS.max_steps):\n",
    "\n",
    "      # Training -----------------------------------------------------------------------------------------------------------------------------------\n",
    "      # Backpropagation using test set\n",
    "\n",
    "      (trainImages, trainLabels) = cifar.getTrainBatch()\n",
    "      (testImages, testLabels) = cifar.getTestBatch()   \n",
    "\n",
    "      _,summary_str = sess.run([train_step, training_summary], feed_dict={x: trainImages, y_: trainLabels})\n",
    "\n",
    "      if step % (FLAGS.log_frequency + 1)== 0 :\n",
    "        summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "      # Validation --------------------------------------------------------------------------------------------------------------------------------\n",
    "      # Monitoring accuracy using validation set\n",
    "\n",
    "      if step % FLAGS.log_frequency == 0:\n",
    "        validation_accuracy, summary_str = sess.run([accuracy, validation_summary], feed_dict={x: testImages, y_: testLabels})\n",
    "        print('step %d, accuracy on validation batch: %g' % (step, validation_accuracy))\n",
    "        summary_writer_validation.add_summary(summary_str, step)\n",
    "\n",
    "      # Save the model checkpoint periodically.\n",
    "      if step % FLAGS.save_model == 0 or (step + 1) == FLAGS.max_steps:\n",
    "        checkpoint_path = os.path.join(FLAGS.train_dir + \"_train\", 'model.ckpt')\n",
    "        saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n",
    "    # --- Train done\n",
    "    # Testing -------------------------------------------------------------------------------------------------------------------------------------- \n",
    "    # Accuracy on TEST set\n",
    "    \n",
    "    # resetting the internal batch indexes\n",
    "    cifar.reset()        \n",
    "    evaluatedImages = 0    \n",
    "    test_accuracy = 0;\n",
    "    nRuns = 0;\n",
    "    \n",
    "    while evaluatedImages != cifar.nTestSamples:\n",
    "        (testImages, testLabels) = cifar.getTestBatch(allowSmallerBatches=True) # don't loop back when we reach the end of the test set\n",
    "        test_accuracy_temp, _ = sess.run([accuracy, test_summary], feed_dict={x: testImages, y_: testLabels})        \n",
    "        \n",
    "        nRuns = nRuns + 1\n",
    "        test_accuracy = test_accuracy + test_accuracy_temp\n",
    "        evaluatedImages = evaluatedImages + testLabels.shape[0]\n",
    "    \n",
    "    test_accuracy = test_accuracy / nRuns\n",
    "print('test set: accuracy on test set: %0.3f' % test_accuracy) \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  tf.app.run(main=main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
